{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNMYZrHSu4LR"
   },
   "source": [
    "## FRIST we get started with \n",
    "\n",
    "If you are using colab, then you can install scrapy from the  using the following command.\n",
    "\n",
    "#### ! pip install scarapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E99E7dj1u4LS"
   },
   "source": [
    "\n",
    "\n",
    "After scrapy installation, open cmd prompt from conda.\n",
    "\n",
    "To create a scrapy project use following command in cmd prompt.\n",
    "\n",
    "#### scrapy startproject Scrape_AmazonReviews\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Once you have created the project, you will find \"Scrape_AmazonReviews\" file in root directory of your system. In which, one is a folder which contains your scrapy code, and other is your scrapy configuration file. Scrapy configuration helps in running and deploying the Scrapy project on a server.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaVJ9yRpu4LS"
   },
   "source": [
    "\n",
    "\n",
    "Once we have the project in place, we need to create a spider. A spider is a chunk of python code that determines, how a web page will be scrapped. It is the main component that crawls different web pages and extracts content out of it. In our case, this will be the code chunk that will perform the task of visiting Amazon and scraping Amazon reviews. To create a spider, you can type in following command in same cmd prompt.\n",
    "\n",
    "#### scrapy genspider amazon_review https://www.amazon.in/\n",
    "\n",
    "This will create python file named \"amazon_review.py\" in your root directory, which you need to place inside \"Scrape_AmazonReviews\\Scrape_AmazonReviews\\spiders\" folder.\n",
    "\n",
    "The \"amazon_review.py\" file contains below scrapy parser code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hC9z_Z_7u4LT"
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class AmazonReviewSpider(scrapy.Spider):\n",
    "    name = 'amazon_review'\n",
    "    allowed_domains = ['amazon.in']\n",
    "    start_urls = ['http://amazon.in']\n",
    "\n",
    "    def parse(self, response):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LejWso4Hu4LU"
   },
   "source": [
    "\n",
    "\n",
    "Spider gets created within a \"spiders\" folder inside the project directory. Once you go into the \"Scrape_AmazonReviews\" folder/project, you will see a directory structure like the one below. \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Scrapy files description:\n",
    "\n",
    "Let us understand the \"Scrape_AmazonReviews\" Scrapy project structure and supporting files inside in a bit more detail. Main files inside Scrapy project directory includes, \n",
    "\n",
    "items.py \n",
    "\n",
    "Items are containers that will be loaded with the scraped data.\n",
    "\n",
    "\n",
    "middleware.py\n",
    "\n",
    "The spider middleware is a framework of hooks into Scrapy’s spider processing mechanism where you can plug custom functionality to process the responses that are sent to Spiders for processing and to handle the requests and items that are generated from spiders.\n",
    "\n",
    "pipelines.py\n",
    "\n",
    "After an item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially. Each item pipeline component is a Python class.\n",
    "\n",
    "settings.py\n",
    "\n",
    "It allows one to customize the behaviour of all Scrapy components, including the core, extensions, pipelines and spiders themselves.\n",
    "\n",
    "spiders folder\n",
    "\n",
    "The Spiders is a directory which contains all spiders/crawlers as Python classes. Whenever one runs/crawls any spider, then scrapy looks into this directory and tries to find the spider with its name provided by the user. Spiders define how a certain site or a group of sites will be scraped, including how to perform the crawl and how to extract data from their pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xm90az4cu4Ld"
   },
   "source": [
    "\n",
    "\n",
    "Analyzing HTML structure of the webpage:\n",
    "\n",
    "For Egs: https://www.amazon.in/product-reviews/9387779262/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&pageNumber=\n",
    "(Extraction of reviews from this web-page)\n",
    "\n",
    "Now, before we actually start writing spider implementation in python for scraping Amazon reviews, we need to identify patterns in the target web page. Below is the page we are trying to scrape which contains different reviews about the product 'My First Library: Boxset of 10 Board Books for Kids' on Amazon. \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta4cQsI0u4Le"
   },
   "source": [
    "We start by opening the web page using the inspect-element feature in the browser. There you can see the HTML code of the web page. After a little bit of exploration, I found the following HTML structure which renders the reviews on the web page. \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZtojrBAu4Le"
   },
   "source": [
    "On the reviews page, there is a division with id \"cm_cr-review_list\". This division has multiple sub-division within which the review content resides. We are planning to extract both star rating and review text from the web page. Upon further inspection, we can see that every review subdivision is further divided into multiple blocks. One of these blocks contains required star ratings, and others includes the text of review needed. By looking more closely, we can easily see that star rating division is represented by the class attribute “review-rating” and review texts are represented by the class “review-text”. All we need to do now is just to pick these patterns up using our Scrapy parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ0sETC8u4Le"
   },
   "source": [
    "\n",
    "\n",
    "Then we need to define a parse function that gets fired up whenever our spider visits a new page. In the parse function, we need to identify patterns in the targeted page structure. Spider then looks for these patterns and extracts them out from the web page. \n",
    "\n",
    "Below is a code sample of Scrapy parser for scraping Amazon reviews. let's name the file as \"extract_reiews.py\" and save it in \"Scrape_AmazonReviews\\Scrape_AmazonReviews\\spiders\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEYw7TzQu4Lf"
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class AmazonReviewsSpider(scrapy.Spider):\n",
    "\n",
    "    # Spider name\n",
    "    name = 'amazon_reviews'\n",
    "\n",
    "    # Domain names to scrape\n",
    "    allowed_domains = ['amazon.in']\n",
    "\n",
    "    # Base URL for the product reviews\n",
    "    myBaseUrl = \"https://www.amazon.in/product-reviews/9387779262/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&pageNumber=\"\n",
    "    start_urls=[]\n",
    "\n",
    "    # Creating list of urls to be scraped by appending page number a the end of base url\n",
    "    for i in range(1,121):\n",
    "        start_urls.append(myBaseUrl+str(i))\n",
    "\n",
    "    # Defining a Scrapy parser\n",
    "    def parse(self, response):\n",
    "            data = response.css('#cm_cr-review_list')\n",
    "            \n",
    "            # Collecting product star ratings\n",
    "            star_rating = data.css('.review-rating')\n",
    "\n",
    "            # Collecting user reviews\n",
    "            comments = data.css('.review-text')\n",
    "            count = 0\n",
    "\n",
    "            # Combining the results\n",
    "            for review in star_rating:\n",
    "                yield{'stars': \n",
    "                      ''.join(review.xpath('.//text()').extract()),\n",
    "                      'comment': \n",
    "                          ''.join(comments[count].xpath(\".//text()\").extract())\n",
    "                     }\n",
    "                count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VSaZ8_zu4Lf"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Finally, we have successfully built our spider. The only task now left is to run this spider. We can run this spider by using the runspider command. It takes to input the spider file to run and the output file to store the collected results. In the case below, spider file is amazon_reviews.py and the output file is amazon_reviews.csv\n",
    "\n",
    "To run this, open cmd prompt and type below command:\n",
    "\n",
    "#### scrapy runspider Scrape_AmazonReviews\\Scrape_AmazonReviews\\spiders\\extract_reviews.py -o extract_reviews.csv\n",
    "\n",
    "The extracted \"extract_reviews.csv\" will get saved to default directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4nXhvjXu4Lg"
   },
   "source": [
    "\n",
    "\n",
    "The extracted reviews file is ready to use and can be open using python as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BugROwhAu4Lg",
    "outputId": "12e62e05-8d7e-49be-ce7a-5e76944b7c7b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  The book b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  It's very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Thats the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  My 2 and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Ordered fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Overpriced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Books are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stars                                            comment\n",
       "0     4.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  The book b...\n",
       "1     4.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Bought thi...\n",
       "2     5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  It's very ...\n",
       "3     3.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Thats the ...\n",
       "4     5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  My 2 and h...\n",
       "...                  ...                                                ...\n",
       "1195  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Ordered fo...\n",
       "1196  4.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice quali...\n",
       "1197  2.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Overpriced...\n",
       "1198  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice books...\n",
       "1199  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Books are ...\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "book=pd.read_csv('extract_reviews.csv')\n",
    "book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrKiXxW-u4Lh"
   },
   "source": [
    "## final test\n",
    "\n",
    "Testing our code for different product reviews. For egs: Bosch washing machine front load with weblink as follows:\n",
    "https://www.amazon.in/Bosch-Inverter-Control-Automatic-Loading/product-reviews/B08SR372S7/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\n",
    "\n",
    "Replace weblink in previous \"extract_reiews.py\" with this one and save file name as extract_reviews_test2.py in the same folder.\n",
    "\n",
    "Then, run cmd and use following command in cmd prompt\n",
    "\n",
    "#### scrapy runspider Scrape_AmazonReviews\\Scrape_AmazonReviews\\spiders\\extract_reviews_test2.py -o extract_reviews_test2.csv \n",
    "\n",
    "And reading it using pandas python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGYe7rHIu4Lh",
    "outputId": "6b3ac0dd-b826-4bcc-c41a-85a38865e435"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  I am total...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Worst serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  I am writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Good one. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  The best w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Very good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Awesome..\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  excellent\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Excellent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stars                                            comment\n",
       "0     1.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  I am total...\n",
       "1     1.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Worst serv...\n",
       "2     5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  I am writi...\n",
       "3     5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Good one. ...\n",
       "4     5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  The best w...\n",
       "...                  ...                                                ...\n",
       "1195  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Nice to re...\n",
       "1196  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Very good ...\n",
       "1197  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Awesome..\\...\n",
       "1198  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  excellent\\...\n",
       "1199  5.0 out of 5 stars  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    \\n  Excellent ...\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2=pd.read_csv('extract_reviews_test2.csv')\n",
    "book2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnIT9um4u4Li"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
